# VideoDB Plugin for Claude Code

Talk to your videos using natural language. Upload, search, edit, generate subtitles, create clips, and more.

> Built on the [VideoDB Python SDK](https://github.com/video-db/videodb-python) and [VideoDB Capture SDK](https://github.com/video-db/videodb-capture-quickstart) | Works with **Claude Code**, **Claude Web**, and the **Claude API**

---

## What You Can Do

| Capability | Description |
|---|---|
| **Upload** | Ingest videos from YouTube, URLs, or local files |
| **Search** | Find moments by what was said (speech) or what was shown (scenes) |
| **Transcripts** | Generate timestamped transcripts from any video |
| **Edit** | Combine clips, trim, add text/image/audio overlays |
| **Subtitles** | Auto-generate and style subtitles |
| **AI Generate** | Create images, video, music, sound effects, and voiceovers from text |
| **Meetings** | Record meetings, extract transcripts, get summaries and action items |
| **Capture** | Record screen, mic, and system audio in real-time with AI transcription and indexing |
| **Stream** | Get playable HLS links for anything you build |

---

## Prerequisites

- **Python 3.9+**
- **VideoDB API key** -- sign up free at [console.videodb.io](https://console.videodb.io) (50 free uploads, no credit card)

---

## Quick Start (Claude Code Plugin)

### 1. Install the plugin

```
/plugin marketplace add video-db/claude-code
/plugin install videodb@videodb
```

### 2. Add your API key

Create a `.env` file inside the skill directory (`skills/videodb/.env`):

```ini
VIDEO_DB_API_KEY=your-api-key-here
```

### 3. Set up the Python environment

The skill auto-runs setup on first use, or you can trigger it manually:

```
/videodb setup the virtual environment
```

This runs `scripts/setup_venv.py` which creates a `.venv/` and installs all dependencies from `requirements.txt`.

### 4. Start using it

```
/videodb upload this YouTube video and give me a transcript
```

You can also just describe what you want -- Claude will load the skill automatically when the task involves video processing.

**More examples:**

```
/videodb search for "product demo" in my latest video
```
```
/videodb add subtitles to my video with white text on black background
```
```
/videodb take clips from 10s-30s and 45s-60s, add a title card, and combine them
```
```
/videodb generate 30 seconds of background music and overlay it on my video
```

---

## Using with Claude Web (claude.ai)

You can use VideoDB with Claude on the web by giving it the SDK reference as project context.

### Setup

1. Create a new [Claude Project](https://claude.ai)
2. In the project knowledge, add the contents of these files:
   - [`SKILL.md`](skills/videodb/SKILL.md) -- core SDK reference and quick-start patterns
   - [`REFERENCE.md`](skills/videodb/REFERENCE.md) -- full API reference
3. Set the project system prompt to:

```
You are a video processing assistant using the VideoDB Python SDK.
Use the provided reference documentation to write correct Python code.
Always use `from dotenv import load_dotenv; load_dotenv()` before `videodb.connect()`.
```

### Usage

Ask Claude to write Python scripts for your video tasks:

- *"Write a Python script that uploads this YouTube video and generates a transcript."*
- *"Create a script that searches for 'product launch' in a video and compiles the matching clips."*
- *"Build a timeline that combines three video clips with a title overlay and background music."*

Claude will generate standalone Python scripts you can run locally with:

```bash
.venv/bin/python your_script.py
```

---

## Using with the Claude API

Use the VideoDB skill as a system prompt for programmatic access via the [Anthropic SDK](https://docs.anthropic.com/en/api/getting-started).

### Setup

1. Read `SKILL.md` and `REFERENCE.md` into your system prompt
2. Send user messages describing video tasks
3. Execute the generated Python code in your environment

### Example

```python
import anthropic

# Load the skill reference as system context
with open("SKILL.md") as f:
    skill_context = f.read()
with open("REFERENCE.md") as f:
    reference_context = f.read()

client = anthropic.Anthropic()

message = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=4096,
    system=f"""You are a video processing assistant using the VideoDB Python SDK.
Write correct, runnable Python code based on user requests.

{skill_context}

{reference_context}""",
    messages=[
        {
            "role": "user",
            "content": "Upload this YouTube video and search for mentions of 'AI': https://www.youtube.com/watch?v=VIDEO_ID"
        }
    ],
)

print(message.content[0].text)
```

### Tips

- Include `SEARCH.md` or `EDITOR.md` in the system prompt when your use case focuses on search or editing
- Add `CAPTURE.md` when your use case involves real-time screen/audio capture
- For token efficiency, use only `SKILL.md` for general tasks -- it covers the most common operations
- Add `GENERATIVE.md` when you need AI-generated media (images, music, voice)

---

## Project Structure

```
plugins/videodb/
├── .claude-plugin/
│   └── plugin.json           # Plugin manifest
├── .gitignore
├── README.md
└── skills/
    └── videodb/
        ├── SKILL.md              # Skill definition (loaded by Claude Code)
        ├── REFERENCE.md          # Complete API reference
        ├── SEARCH.md             # Search and indexing guide
        ├── EDITOR.md             # Timeline editing guide
        ├── GENERATIVE.md         # AI generation guide
        ├── MEETINGS.md           # Meeting recording and analysis
        ├── RTSTREAM.md           # Real-time streaming guide
        ├── CAPTURE.md            # Real-time capture architecture guide
        ├── USE_CASES.md          # End-to-end workflow examples
        ├── requirements.txt      # Python dependencies
        ├── .env.example          # Environment variable template
        └── scripts/
            ├── setup_venv.py         # Virtual environment setup
            ├── setup.py              # Dependency checker
            ├── check_connection.py   # API key verification
            ├── batch_upload.py       # Bulk upload from URL list or directory
            ├── search_and_compile.py # Search + compile into stream
            ├── extract_clips.py      # Extract clips by timestamp
            ├── backend.py            # Capture backend (Flask + Cloudflare tunnel)
            ├── client.py             # Capture client (screen + audio recording)
            ├── test_editor.py        # Integration test: timeline editing
            ├── test_meetings.py      # Integration test: meeting analysis
            └── test_rtstream.py      # Integration test: streaming
```

---

## Documentation

| Guide | What's Inside |
|---|---|
| [SKILL.md](skills/videodb/SKILL.md) | Skill definition and quick reference |
| [REFERENCE.md](skills/videodb/REFERENCE.md) | Complete API reference for all objects and methods |
| [SEARCH.md](skills/videodb/SEARCH.md) | Semantic, keyword, and scene-based search |
| [EDITOR.md](skills/videodb/EDITOR.md) | Timeline editing with overlays, limitations |
| [GENERATIVE.md](skills/videodb/GENERATIVE.md) | AI-generated images, video, music, voice, and text |
| [MEETINGS.md](skills/videodb/MEETINGS.md) | Meeting recording, transcription, and analysis |
| [RTSTREAM.md](skills/videodb/RTSTREAM.md) | Real-time HLS streaming |
| [CAPTURE.md](skills/videodb/CAPTURE.md) | Real-time capture architecture and AI pipelines |
| [USE_CASES.md](skills/videodb/USE_CASES.md) | End-to-end workflow examples |

---

## Real-Time Capture

The plugin includes a ready-to-run capture setup powered by the [VideoDB Capture SDK](https://github.com/video-db/videodb-capture-quickstart). It uses a two-process model:

- **`scripts/backend.py`** -- Flask server with a Cloudflare tunnel that creates capture sessions, handles webhook events, and starts AI pipelines (transcription, audio indexing, visual indexing)
- **`scripts/client.py`** -- Captures screen, mic, and system audio using `CaptureClient` and streams to VideoDB for real-time processing

### Quick start

```bash
# Terminal 1: start the backend
.venv/bin/python scripts/backend.py

# Terminal 2: start the client
.venv/bin/python scripts/client.py
```

The backend automatically creates a Cloudflare tunnel for the webhook URL. The client requests device permissions, discovers channels, and begins streaming. Press Enter in the client terminal to stop recording.

See [CAPTURE.md](skills/videodb/CAPTURE.md) for the full architecture guide, AI pipeline setup, and webhook event handling.

---

## Utility Scripts

Run these from the `skills/videodb/` directory:

```bash
# Upload multiple files from a URL list
.venv/bin/python scripts/batch_upload.py --urls urls.txt --collection "My Project"

# Search inside a video and compile results
.venv/bin/python scripts/search_and_compile.py --video-id VIDEO_ID --query "product demo"

# Extract clips by timestamp ranges
.venv/bin/python scripts/extract_clips.py --video-id VIDEO_ID --timestamps "10.0-25.0,45.0-60.0"

# Start the capture backend (Flask + Cloudflare tunnel)
.venv/bin/python scripts/backend.py

# Start the capture client (screen + audio recording)
.venv/bin/python scripts/client.py
```

---

## License

This plugin is provided as-is for use with Claude. The VideoDB SDK is governed by its own [license](https://github.com/video-db/videodb-python/blob/main/LICENSE).
